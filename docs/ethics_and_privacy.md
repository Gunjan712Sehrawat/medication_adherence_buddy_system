# Ethics and Privacy Guidelines

## ğŸ” Commitment to Ethical AI in Healthcare

The Medication Adherence Risk Scoring System is designed with privacy, ethics, and patient safety as foundational principles. This document outlines our approach to responsible AI deployment in healthcare settings.

---

## ğŸ“‹ Table of Contents

1. [Informed Consent Flow](#informed-consent-flow)
2. [Data Privacy & Storage](#data-privacy--storage)
3. [Risk Scores vs. Diagnoses](#risk-scores-vs-diagnoses)
4. [Patient Rights & Opt-Out](#patient-rights--opt-out)
5. [Fairness & Bias Mitigation](#fairness--bias-mitigation)
6. [Transparency & Explainability](#transparency--explainability)
7. [Clinical Integration Guidelines](#clinical-integration-guidelines)
8. [Ethical Use Checklist](#ethical-use-checklist)

---

## 1. Informed Consent Flow

### ğŸ¤ Required Consent Process

**Before deploying this system, patients MUST provide informed consent that includes:**

#### A. What Patients Should Be Told

```
PATIENT CONSENT TEMPLATE

You are being offered participation in a medication adherence 
monitoring program that uses artificial intelligence (AI) to help 
identify when you might need additional support.

WHAT THIS PROGRAM DOES:
â€¢ Analyzes your responses to automated reminder calls and text messages
â€¢ Uses patterns to estimate if you might benefit from extra help
â€¢ Alerts healthcare staff if you may need support with your medications

WHAT DATA IS COLLECTED:
â€¢ Response patterns to IVR (automated phone) calls
â€¢ Text message read receipts and response times
â€¢ Prescription refill dates (already in your medical record)
â€¢ Basic demographics (age, number of medications)

WHAT DATA IS NOT COLLECTED:
â€¢ The actual content of your conversations
â€¢ Your specific medical conditions or diagnoses
â€¢ Your location or personal identifying information beyond what's 
  already in your medical record

HOW YOUR PRIVACY IS PROTECTED:
â€¢ Your identity is anonymized in the AI system
â€¢ No raw health data is stored by the AI
â€¢ All data is encrypted and HIPAA-compliant
â€¢ Only authorized healthcare staff can see your results

WHAT HAPPENS WITH THE RESULTS:
â€¢ A "risk score" is generated (low, medium, or high)
â€¢ This is NOT a medical diagnosis
â€¢ Healthcare staff use this to decide if you need a check-in call
â€¢ You always have the right to speak with a person

YOUR RIGHTS:
â€¢ You can opt-out at any time without affecting your care
â€¢ You can request your data be deleted
â€¢ You can ask how your score was calculated
â€¢ You can request human-only contact (no AI)

DO YOU CONSENT TO PARTICIPATE? â–¡ YES  â–¡ NO

Signature: _______________ Date: _______________
```

#### B. Consent Implementation Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Patient Enrollment  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Present Consent     â”‚
â”‚ Form (Written/Digital)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Patient      â”‚â—„â”€â”€â”€â”€ Provide educational materials
    â”‚ Reviews      â”‚      Allow time for questions
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Questions &  â”‚â—„â”€â”€â”€â”€ Answer by qualified staff
    â”‚ Clarificationâ”‚      NOT automated responses
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Patient      â”‚
    â”‚ Decision     â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚
    â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ACCEPT â”‚   â”‚DECLINE â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â”‚            â”‚
    â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Documentâ”‚   â”‚ Standard   â”‚
â”‚Consent â”‚   â”‚ Care Only  â”‚
â”‚in EHR  â”‚   â”‚ (No AI)    â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Activate AI        â”‚
â”‚ Monitoring with    â”‚
â”‚ Patient ID in      â”‚
â”‚ Consented List     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### C. Ongoing Consent Requirements

- **Annual Re-consent**: Review consent yearly or when system updates
- **Notification of Changes**: Alert patients to any material changes
- **Withdrawal Process**: Simple, immediate opt-out mechanism
- **Documentation**: All consent tracked in audit logs

---

## 2. Data Privacy & Storage

### ğŸš« NO Raw Health Data Stored

**CRITICAL PRINCIPLE**: This AI system does NOT store raw protected health information (PHI).

#### What IS Stored

```python
# EXAMPLE: Stored data (anonymized, aggregated)
{
    "patient_id": "HASH_ae3f891b2c",  # Hashed identifier
    "ivr_calls_answered": 3,           # Count only
    "ivr_calls_missed": 2,             # Count only
    "sms_read_count": 5,               # Count only
    "avg_response_time_hrs": 12.5,     # Aggregated metric
    "days_since_rx": 14,               # Relative time
    "age_bracket": "65-75",            # Binned, not exact
    "medication_count": 3,             # Count only
    "risk_score": 0.72,                # Calculated score
    "timestamp": "2026-02-05T10:00:00Z"
}
```

#### What IS NOT Stored

âŒ Patient names  
âŒ Medical record numbers (MRNs) - only irreversible hashes  
âŒ Phone numbers or contact information  
âŒ Specific medical diagnoses  
âŒ Medication names or details  
âŒ Clinical notes or free text  
âŒ Audio recordings of calls  
âŒ Full message content  
âŒ Addresses or precise locations  
âŒ Social security numbers  
âŒ Insurance information  

#### Data Flow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EHR System   â”‚ (Source of truth - PHI stays here)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ API Call: Get anonymized features
       â”‚ only for consented patients
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI System    â”‚ (Receives only aggregated, 
â”‚ (This Repo)  â”‚  anonymized features)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Returns: Risk score + explanation
       â”‚ (No PHI returned)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EHR System   â”‚ (Stores risk score linked to 
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  patient via internal ID)

KEY: PHI never leaves EHR system
     AI sees only anonymized, aggregated data
     Link between hash and patient maintained 
     ONLY in EHR (not in AI system)
```

#### Storage Policies

| Data Type | Retention Period | Encryption | Access Control |
|-----------|------------------|------------|----------------|
| Aggregated Features | 90 days | AES-256 | Role-based |
| Risk Scores | 1 year | AES-256 | Clinical staff only |
| Audit Logs | 7 years | AES-256 | Admin only |
| Model Artifacts | Until superseded | AES-256 | ML team only |
| Raw PHI | **NEVER STORED** | N/A | N/A |

#### Data Deletion Process

Patients can request deletion:

1. **Request Submitted** â†’ Logged in audit trail
2. **Verification** â†’ Confirm patient identity
3. **Deletion** â†’ All anonymized records purged within 48 hours
4. **Confirmation** â†’ Patient notified of completion
5. **Audit** â†’ Deletion logged (but not reversible)

---

## 3. Risk Scores vs. Diagnoses

### âš ï¸ CRITICAL DISTINCTION

**Risk scores ARE:**
- Predictive estimates of non-adherence probability
- Decision support tools for healthcare staff
- Indicators that a patient *may* benefit from outreach
- Based on behavioral patterns and statistical correlations

**Risk scores ARE NOT:**
- Medical diagnoses
- Definitive determinations of patient behavior
- Substitutes for clinical judgment
- Guaranteed predictions of future outcomes
- Suitable for automated treatment decisions

#### Required Disclaimers

**In System Interface:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âš ï¸ CLINICAL DECISION SUPPORT TOOL           â”‚
â”‚                                             â”‚
â”‚ This risk score is a PREDICTION, not a     â”‚
â”‚ diagnosis. It should be used alongside     â”‚
â”‚ clinical judgment, not as a replacement.   â”‚
â”‚                                             â”‚
â”‚ Always verify with patient contact before  â”‚
â”‚ taking action. False positives occur.      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**In Patient Communications:**
```
"Our system suggested you might benefit from a check-in 
call about your medications. This is based on patterns 
we've observed, not a determination that you've missed 
doses. Would you like to discuss your medication routine?"

NOT: "Our system detected you're not taking your medications."
```

#### Preventing Misuse

**PROHIBITED Uses:**
- âŒ Denying care or coverage based on risk scores
- âŒ Disciplinary action against patients
- âŒ Automated medication changes
- âŒ Billing or insurance determinations
- âŒ Legal or employment decisions
- âŒ Sharing with non-clinical third parties

**APPROPRIATE Uses:**
- âœ… Prioritizing outreach calls when staff time is limited
- âœ… Identifying patients who may need extra support
- âœ… Triggering human review and follow-up
- âœ… Quality improvement initiatives (aggregated only)
- âœ… Research (with additional consent and IRB approval)

#### Clinical Workflow Integration

```
AI Risk Score Generated
        â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Is scoreâ”‚
   â”‚ HIGH?   â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚ YES
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Clinician      â”‚
â”‚ Review Requiredâ”‚ â† Human in the loop
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Clinical       â”‚
â”‚ Judgment:      â”‚
â”‚ - Review chart â”‚
â”‚ - Consider     â”‚
â”‚   context      â”‚
â”‚ - Decide actionâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Contact â”‚ â”‚No Action â”‚
â”‚Patient â”‚ â”‚Needed    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NEVER: Automated intervention without human review
```

---

## 4. Patient Rights & Opt-Out

### ğŸšª Guaranteed Patient Rights

Every patient has the RIGHT to:

1. **Know** they are being monitored by AI
2. **Understand** how the system works (in plain language)
3. **Ask** how their specific score was calculated
4. **Opt-out** at any time without penalty
5. **Request** human-only contact
6. **Access** their data and scores
7. **Correct** inaccurate information
8. **Delete** their data from the system
9. **Complain** without retaliation
10. **Receive care** regardless of participation

### âœ‹ Opt-Out Mechanism

#### Multiple Opt-Out Channels

Patients can opt-out via:
- âœ… Phone call to support line
- âœ… Patient portal button (one-click)
- âœ… Email request
- âœ… In-person request to any staff
- âœ… Written form
- âœ… Text message keyword (e.g., "STOP AI")

#### Opt-Out Processing

```python
# Example implementation
def process_opt_out(patient_id: str, method: str):
    """
    Process patient opt-out request
    Must complete within 24 hours
    """
    # 1. Immediate: Stop AI monitoring
    disable_ai_monitoring(patient_id)
    
    # 2. Log the request
    audit_log.record({
        'action': 'opt_out',
        'patient_id': hash(patient_id),
        'method': method,
        'timestamp': datetime.now(),
        'processed_by': 'system'
    })
    
    # 3. Delete historical data (per policy)
    delete_patient_data(patient_id, retain_audit=True)
    
    # 4. Notify patient
    send_confirmation(patient_id, 
        "Your opt-out request has been processed. AI monitoring "
        "has been disabled. You will continue to receive standard "
        "care. This does not affect your healthcare services."
    )
    
    # 5. Notify care team
    notify_care_team(patient_id,
        "Patient has opted out of AI monitoring. "
        "Use standard care protocols only."
    )
    
    # 6. Flag in EHR (prevent re-enrollment)
    mark_as_opted_out(patient_id)
```

#### Opt-Out Timeline

| Timeframe | Action |
|-----------|--------|
| Immediate | AI monitoring stops |
| 24 hours | Patient confirmation sent |
| 48 hours | Data deletion complete |
| 7 days | Audit trail finalized |

#### No Penalty Policy

**GUARANTEED**: Opting out does NOT affect:
- Quality of care received
- Access to services
- Relationship with providers
- Insurance coverage
- Future care options
- Ability to opt back in later

---

## 5. Fairness & Bias Mitigation

### âš–ï¸ Commitment to Equity

We recognize that AI systems can perpetuate or amplify existing healthcare disparities. Our approach:

#### Monitored Protected Attributes

Monitor (but NOT use as features) for disparate impact:
- Race/ethnicity
- Gender identity
- Age
- Socioeconomic status
- Language preference
- Geographic location
- Insurance type
- Disability status

#### Regular Bias Audits

**Quarterly Review:**
```python
def equity_audit(predictions_df):
    """
    Check for disparate impact across demographic groups
    """
    for protected_attr in ['race', 'gender', 'age_group', 'zip_code']:
        # Calculate metrics by group
        group_metrics = predictions_df.groupby(protected_attr).agg({
            'risk_score': ['mean', 'std'],
            'false_positive_rate': 'mean',
            'false_negative_rate': 'mean'
        })
        
        # Check for disparities
        if max_difference(group_metrics) > THRESHOLD:
            flag_for_review(protected_attr, group_metrics)
            consider_recalibration()
```

**Action Triggers:**
- >10% difference in false positive rates â†’ Mandatory review
- >15% difference in false negative rates â†’ Mandatory review
- Systematic under/over-prediction â†’ Model retraining

#### Fairness Constraints

- **No use of protected attributes** as direct features
- **Proxy detection**: Monitor for correlated features
- **Calibration by group**: Ensure scores are equally valid across groups
- **Equal threshold option**: Adjust thresholds per group if needed

---

## 6. Transparency & Explainability

### ğŸ” Right to Explanation

**Every patient and clinician can access:**

1. **Global Model Explanation**
   - What factors the model considers (in general)
   - How the model was trained and validated
   - Performance metrics (accuracy, false positive rate)

2. **Individual Prediction Explanation**
   ```
   EXAMPLE PATIENT EXPLANATION:
   
   Your risk score: 0.72 (HIGH)
   
   This score is based on:
   1. Missed 4 out of 5 IVR reminder calls (60%)
   2. Read only 3 out of 10 text reminders (30%)
   3. Prescription refill is 3 days overdue
   
   What this means:
   - These patterns suggest you may benefit from extra support
   - This is NOT a determination that you're not taking medications
   - A staff member will reach out to check if you need help
   
   What you can do:
   - Update us if your contact info changed
   - Let us know if reminders aren't working for you
   - Request a different contact method
   ```

3. **Model Card**
   - Intended use cases
   - Known limitations
   - Performance by demographic group
   - Update history

---

## 7. Clinical Integration Guidelines

### ğŸ‘¨â€âš•ï¸ For Healthcare Providers

#### DO:
- âœ… Use scores as conversation starters with patients
- âœ… Combine AI insights with clinical judgment
- âœ… Verify before taking action
- âœ… Document your reasoning in clinical notes
- âœ… Explain the tool to patients when discussing scores
- âœ… Report system errors or concerns

#### DON'T:
- âŒ Treat scores as definitive diagnoses
- âŒ Skip verification with the patient
- âŒ Use scores for punitive purposes
- âŒ Share scores with non-clinical staff
- âŒ Override patient preferences based on scores
- âŒ Ignore contextual factors the AI can't see

#### Escalation Protocol

```
HIGH Risk Score Generated
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pharmacist/Nurse  â”‚
â”‚ Review Within 24hrâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Patient Contact   â”‚
â”‚ Attempt (phone)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚ Reached?â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
    YES  â”‚  NO
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
    â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Discuss  â”‚ â”‚ 2nd      â”‚
â”‚concerns â”‚ â”‚ Attempt  â”‚
â”‚& assist â”‚ â”‚ Next Day â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ If still â”‚
            â”‚ no reach:â”‚
            â”‚ Inform   â”‚
            â”‚ Provider â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8. Ethical Use Checklist

### âœ… Pre-Deployment Requirements

Before deploying this system, ensure:

**Legal & Compliance:**
- [ ] IRB/Ethics board approval obtained (if required)
- [ ] HIPAA compliance verified
- [ ] Legal review of consent forms completed
- [ ] Data privacy impact assessment conducted
- [ ] Contracts with all vendors reviewed

**Technical:**
- [ ] Model validated on institution's patient population
- [ ] Bias audit completed and documented
- [ ] Security penetration testing passed
- [ ] Disaster recovery plan in place
- [ ] Model performance monitoring configured

**Operational:**
- [ ] Staff training completed (all users)
- [ ] Clinical workflows documented
- [ ] Escalation procedures defined
- [ ] Patient education materials prepared
- [ ] Opt-out mechanism tested and verified

**Ethical:**
- [ ] Informed consent process implemented
- [ ] Patient rights clearly communicated
- [ ] Fairness metrics established and monitored
- [ ] Transparency documentation published
- [ ] External ethics review completed (recommended)

### ğŸ“‹ Ongoing Monitoring

**Monthly:**
- Review opt-out requests and reasons
- Check false positive/negative rates
- Monitor patient complaints
- Verify consent documentation

**Quarterly:**
- Bias and fairness audit
- Staff feedback sessions
- Patient satisfaction survey
- Model performance review

**Annually:**
- External ethics audit
- Update consent forms if needed
- Comprehensive system review
- Publication of transparency report

---

## ğŸš¨ Incident Response

### When Things Go Wrong

**Report immediately if:**
- Data breach or unauthorized access
- Systematic errors in predictions
- Evidence of bias or discrimination
- Patient harm potentially related to system
- Violation of consent or opt-out

**Response Protocol:**
1. **Stop**: Disable system if patient safety at risk
2. **Report**: Notify compliance officer immediately
3. **Investigate**: Determine root cause
4. **Remediate**: Fix the issue
5. **Notify**: Alert affected patients if required
6. **Document**: Full incident report
7. **Learn**: Update procedures to prevent recurrence

---

## ğŸ“ Contact for Ethics Concerns

**Patients:** Contact patient advocate or privacy officer  
**Staff:** Report to ethics committee or compliance officer  
**Researchers:** Consult IRB before using data  
**Developers:** Review with ethics board before major changes  

---

## ğŸ“š Additional Resources

- [HIPAA Privacy Rule](https://www.hhs.gov/hipaa/for-professionals/privacy/)
- [FDA Guidance on AI/ML in Medical Devices](https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices)
- [WHO Ethics & Governance of AI for Health](https://www.who.int/publications/i/item/9789240029200)
- [ACM Code of Ethics](https://www.acm.org/code-of-ethics)

---

## ğŸ¯ Summary: Core Ethical Principles

1. **Respect for Autonomy**: Informed consent, opt-out rights
2. **Beneficence**: Design to help, not harm patients
3. **Non-maleficence**: Minimize false alerts and discrimination
4. **Justice**: Fair treatment across all patient groups
5. **Privacy**: No raw PHI stored, strong data protection
6. **Transparency**: Explainable predictions, open about limitations
7. **Accountability**: Clear responsibility, incident response

---

**This document should be reviewed and updated annually or when significant changes occur.**

**Version**: 1.0.0  
**Last Updated**: February 2026  
**Next Review Date**: February 2027
